{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WDNdzMDVmb4A"
      },
      "outputs": [],
      "source": [
        "from io import open\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "import random\n",
        "import unicodedata\n",
        "import string\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "import numpy\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import Vocab , build_vocab_from_iterator\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install wandb"
      ],
      "metadata": {
        "id": "IRcfmLX_m-lB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "LfZ-Mc8Vm_7m"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "NOASGr2TnCzR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GeyROqenHBn",
        "outputId": "b9da7eb2-2a45-4383-adfe-99a2dba3dc43"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwf7ch9nnMUS",
        "outputId": "dbb5af6c-aa95-4ed3-97c8-a2eecb238b32"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq \"/content/drive/My Drive/Colab Notebooks/aksharantar_sampled.zip\" -d \"/content\""
      ],
      "metadata": {
        "id": "Uf11uGBinQjm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FMVqFi8GnXHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.char2index = {'#': 0, '$': 1, '^': 2}\n",
        "        self.name = name\n",
        "        self.n_chars = 3  # Count\n",
        "        self.char2count = {'#': 1, '$': 1, '^': 1}\n",
        "        self.data = {}\n",
        "        self.index2char = {0: '#', 1: '$', 2: '^'}    \n",
        "        \n",
        "\n",
        "    def addWord(self, word):\n",
        "        for char in word:\n",
        "            self.addChar(char)\n",
        "\n",
        "    def addChar(self, char):\n",
        "        if char in self.char2index:\n",
        "            self.char2count[char] += 1\n",
        "        else:\n",
        "            self.char2index[char] = self.n_chars\n",
        "            self.index2char[self.n_chars] = char\n",
        "            self.n_chars += 1\n",
        "            self.char2count[char] = 1"
      ],
      "metadata": {
        "id": "SxWTVLRBk7Jp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# return max length of input and output words\n",
        "def maxLength(data):\n",
        "    size=len(data)\n",
        "    ip_mlen, op_mlen = 0, 0\n",
        "\n",
        "    for i in range(size):\n",
        "        input = data[0][i]\n",
        "        output = data[1][i]\n",
        "        x= len(input)\n",
        "        if(x>ip_mlen):\n",
        "            ip_mlen=x\n",
        "        y= len(output)\n",
        "        if(y>op_mlen):\n",
        "            op_mlen=y\n",
        "\n",
        "    return ip_mlen, op_mlen"
      ],
      "metadata": {
        "id": "IBxsaS45nvLP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(data, input_lang, output_lang):\n",
        "    x= len(data)\n",
        "    maxlenInput, maxlenOutput = maxLength(data)\n",
        "    maxlenInput = 25\n",
        "    input = numpy.zeros((x, maxlenInput ))\n",
        "    output = numpy.zeros((x, maxlenOutput + 2))\n",
        "    # maxlenInput, maxlenOutput = maxLength(data)\n",
        "    unknown = input_lang.char2index['$']\n",
        "\n",
        "    for i in range(x):   \n",
        "        b=maxlenInput + 1\n",
        "        ip = data[0][i][:maxlenInput] \n",
        "        # ip = data[0][i].ljust(b, '#')\n",
        "        c=maxlenOutput + 2\n",
        "        op = '^' + data[1][i]\n",
        "        op = op.ljust(c, '#')\n",
        "        \n",
        "        b=enumerate(ip)\n",
        "        for index, char in b:\n",
        "            r= input_lang.char2index[char]\n",
        "            if input_lang.char2index.get(char) is not None:\n",
        "                input[i][index] = r\n",
        "            else:\n",
        "                input[i][index] = unknown\n",
        "        \n",
        "\n",
        "        c=enumerate(op)\n",
        "        for index, char in c:\n",
        "            s= output_lang.char2index[char]\n",
        "            if output_lang.char2index.get(char) is not None:\n",
        "                output[i][index] = s\n",
        "            else:\n",
        "                output[i][index] = unknown  \n",
        "\n",
        "    print(input.shape)\n",
        "    inp=torch.from_numpy(input)\n",
        "    print(output.shape)\n",
        "    \n",
        "    out= torch.from_numpy(output)\n",
        "    return TensorDataset(inp,out )\n"
      ],
      "metadata": {
        "id": "-Fp_EGK5nnsX"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadData(lang):\n",
        "    input_lang = Lang('eng')\n",
        "    train_df = pd.read_csv(f\"/content/aksharantar_sampled/{lang}/{lang}_train.csv\", header = None)\n",
        "    output_lang = Lang(lang)\n",
        "    \n",
        "    # add the words to the respective languages\n",
        "    size=len(train_df)\n",
        "    for i in range(size):\n",
        "        x=train_df[0][i]\n",
        "        input_lang.addWord(x)\n",
        "        y=train_df[1][i]\n",
        "        output_lang.addWord(y)\n",
        "\n",
        "    \n",
        "    trainDataset = preprocess(train_df, input_lang, output_lang)\n",
        "    val_df = pd.read_csv(f\"/content/aksharantar_sampled/{lang}/{lang}_valid.csv\", header = None)\n",
        "    valDataset = preprocess(val_df, input_lang, output_lang)\n",
        "    test_df = pd.read_csv(f\"/content/aksharantar_sampled/{lang}/{lang}_test.csv\", header = None)\n",
        "    target_characters = set()\n",
        "    testDataset = preprocess(test_df, input_lang, output_lang)\n",
        "    \n",
        "    return trainDataset, testDataset, valDataset, input_lang, output_lang\n",
        "    \n",
        "trainData, testData, valData, ipLang, opLang = loadData('tel')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW7CVkLPn52P",
        "outputId": "6c9e3d8a-ad4b-4961-ac6e-909bf78f5557"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(51200, 25)\n",
            "(51200, 23)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4096, 25)\n",
            "(4096, 21)\n",
            "(4096, 25)\n",
            "(4096, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(trainData)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPoiP69roGOD",
        "outputId": "d8407dd1-cef1-4db2-e3a5-5877a6c34139"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51200"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login(key =\"ab8429eef239aaf26799fd710e5ea6aec30ab090\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1gjSS7WoNY2",
        "outputId": "1bd4f3c6-e649-4663-9815-b94d1af67883"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "  'name':\"my-sweep\",\n",
        "  'method': 'bayes',\n",
        "  'metric': {\n",
        "        'name': 'val_accuracy',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "  'parameters': {\n",
        "        'epochs':{\n",
        "            'values': [10, 15, 20]\n",
        "        },\n",
        "        'learn_rate': {\n",
        "            'values': [0.00001, 0.0001]\n",
        "        },\n",
        "        'cell_type':{\n",
        "            'values':[\"RNN\", \"LSTM\", \"GRU\"]\n",
        "        },\n",
        "        'num_decoders':{\n",
        "            'values': [1,2]\n",
        "        },\n",
        "        'embedding_dim': {\n",
        "            'values': [64, 128, 256]\n",
        "        },\n",
        "        'bidirectional':{\n",
        "            'values' : [\"Yes\",\"No\"]\n",
        "        },\n",
        "        'batch_size':{\n",
        "            'values':[ 64, 128, 256]\n",
        "        },\n",
        "        'hidden_dim':{\n",
        "            'values':[64, 128, 256]\n",
        "        },\n",
        "        'attention':{\n",
        "            'values': [\"Yes\",\"No\"]\n",
        "        },\n",
        "        'teach_ratio':{\n",
        "            'values':[0.5]\n",
        "        },\n",
        "        'num_encoders':{\n",
        "            'values': [1]\n",
        "        },\n",
        "        'dropout':{\n",
        "            'values':[0, 0.1, 0.2]\n",
        "        }\n",
        "                  \n",
        "    }\n",
        "}\n",
        "\n",
        "config_defaults={\n",
        "    'num_decoders': 3,\n",
        "    'learn_rate' : 0.0001,\n",
        "    'bidirectional': 'Yes',\n",
        "    'embedding_dim': 32,\n",
        "    'teach_ratio': 0.5,\n",
        "    'cell_type': \"LSTM\",\n",
        "    'hidden_dim' : 128,\n",
        "    'num_encoders': 2,\n",
        "    'attention': \"Yes\",\n",
        "    'epochs': 10,\n",
        "    'batch_size': 16,\n",
        "    'attention': \"Yes\",\n",
        "    'dropout': 0.2\n",
        "    \n",
        "}"
      ],
      "metadata": {
        "id": "dzyeRw4CoQzo"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyEncoder(nn.Module):\n",
        "    # MyEncoder class represents the encoder component of a sequence-to-sequence model.\n",
        "    def __init__(self, input_dim, hidden_dim, embedding_dim, \n",
        "                 num_layers, cell_type,\n",
        "                  bidirectional, dropout, batch_size) :\n",
        "        # Initialize variables\n",
        "        super(MyEncoder, self).__init__()\n",
        "        x= hidden_dim\n",
        "        self.embedding = nn.Embedding(num_embeddings=input_dim,embedding_dim= embedding_dim)\n",
        "        self.hidden_dim = x\n",
        "        y= num_layers\n",
        "        self.num_layers = y\n",
        "        self.bidirectional = True if bidirectional == 'Yes' else False\n",
        "        p = embedding_dim\n",
        "        self.embedding_dim= p\n",
        "        n= cell_type\n",
        "        self.cell_type = n\n",
        "        m= batch_size\n",
        "        self.batch_size = m\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        if self.cell_type == \"GRU\":\n",
        "            gr= nn.GRU(embedding_dim, hidden_dim, num_layers=num_layers, bidirectional=self.bidirectional, dropout=dropout)\n",
        "            self.rnn = gr\n",
        "        elif self.cell_type == \"LSTM\":\n",
        "            ls=nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, bidirectional=self.bidirectional, dropout=dropout)\n",
        "            self.rnn = ls\n",
        "        elif self.cell_type == \"RNN\":\n",
        "            rn=nn.RNN(embedding_dim, hidden_dim, num_layers=num_layers, bidirectional=self.bidirectional, dropout=dropout)\n",
        "            self.rnn = rn\n",
        "    # Initializing the initial hidden state for the encoder\n",
        "    def initialize_hidden(self):\n",
        "        num_directions = 2 if self.bidirectional else 1\n",
        "        if self.cell_type != \"LSTM\":\n",
        "            return torch.zeros(self.num_layers * num_directions, self.batch_size, self.hidden_dim, device=device)\n",
        "        else:\n",
        "            val=self.num_layers * num_directions\n",
        "            return (torch.zeros(val, self.batch_size, self.hidden_dim, device=device),\n",
        "                    torch.zeros(val, self.batch_size, self.hidden_dim, device=device))\n",
        "            \n",
        "    # Perform the forward pass of the encoder\n",
        "    def forward(self, input, hidden): # input shape (seq_len, batch_size) hidden shape tuple for lstm, otherwise single\n",
        "        output = self.dropout(self.embedding(input.long()).view(-1,self.batch_size, self.embedding_dim)) # output shape (seq_len, batch_size, embedding size)\n",
        "\n",
        "        output, hidden = self.rnn(output, hidden) # for LSTM hidden is a tuple\n",
        "        if self.bidirectional:\n",
        "            if self.cell_type != \"LSTM\":\n",
        "                hidden=hidden.resize(2,self.num_layers,self.batch_size,self.hidden_dim)\n",
        "                vc=torch.add(hidden[0],hidden[1])\n",
        "                hidden=vc/2\n",
        "            else:\n",
        "                hidden_state = hidden[0].resize(2,self.num_layers,self.batch_size,self.hidden_dim)\n",
        "                ap=torch.add(hidden_state[0],hidden_state[1])\n",
        "                cell_state = hidden[1].resize(2,self.num_layers,self.batch_size,self.hidden_dim)\n",
        "                tg=torch.add(cell_state[0],cell_state[1])\n",
        "                hidden = (ap/2,tg/2)\n",
        "\n",
        "            split_tensor= torch.split(output, self.hidden_dim, dim=-1)\n",
        "            output=torch.add(split_tensor[0],split_tensor[1])/2  \n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "oi7vNQWfol8k"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDecoder(nn.Module):\n",
        "    def __init__(self, hidden_dim, output_size, embedding_dim, num_layers, \n",
        "                 cell_type, dropout, batch_size):\n",
        "        # Initialize variables\n",
        "        super(MyDecoder, self).__init__()\n",
        "        m= hidden_dim\n",
        "        self.embedding = nn.Embedding(output_size, embedding_dim)\n",
        "        self.hidden_dim = m\n",
        "        n= num_layers\n",
        "        self.num_layers = n\n",
        "        p= batch_size\n",
        "        self.batch_size = p\n",
        "        q=embedding_dim\n",
        "        self.embedding_dim=q\n",
        "        o= cell_type.lower()\n",
        "        self.cell_type = o\n",
        "        \n",
        "        if self.cell_type == \"gru\":\n",
        "            gr= nn.GRU(embedding_dim, hidden_dim, num_layers=num_layers, dropout=dropout)\n",
        "            self.rnn = gr\n",
        "        elif self.cell_type == \"lstm\":\n",
        "            ls= nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, dropout=dropout)\n",
        "            self.rnn = ls\n",
        "        else:\n",
        "            rn=nn.RNN(embedding_dim, hidden_dim, num_layers=num_layers, dropout=dropout)\n",
        "            self.rnn = rn\n",
        "\n",
        "        r= nn.Linear(hidden_dim, output_size)\n",
        "        self.out = r \n",
        "        s= nn.LogSoftmax(dim=2)\n",
        "        self.softmax = s\n",
        "    # Perform the forward pass of the decoder\n",
        "    def forward(self, input, hidden):\n",
        "        output = F.relu(self.embedding(input.long()).view(-1, self.batch_size, self.embedding_dim))\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "        val=self.out(output)\n",
        "        output = self.softmax(val)\n",
        "        return output, hidden\n"
      ],
      "metadata": {
        "id": "zdUEI0Kwov1P"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_dim, output_size, embedding_dim, num_layers,\n",
        "                 cell_type, dropout, batch_size, max_length):\n",
        "        \n",
        "        super(AttentionDecoderRNN, self).__init__()\n",
        "        hd=hidden_dim\n",
        "        self.hidden_dim = hd\n",
        "        nl=num_layers\n",
        "        self.num_layers = nl\n",
        "        ct=cell_type\n",
        "        self.cell_type = ct\n",
        "        bs= batch_size\n",
        "        self.batch_size =bs\n",
        "        ed=embedding_dim\n",
        "        self.embedding_dim = ed\n",
        "        self.embedding = nn.Embedding(output_size, embedding_dim)\n",
        "        ml= max_length\n",
        "        self.max_length =ml\n",
        "        self.attention = nn.Linear(hidden_dim + embedding_dim, self.max_length)\n",
        "        dp=dropout\n",
        "        self.dropout = dp\n",
        "        self.dropout = nn.Dropout(self.dropout)\n",
        "        he=hidden_dim + embedding_dim\n",
        "        self.attention_combine = nn.Linear(he, hidden_dim)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        if self.cell_type == \"GRU\":\n",
        "            gr=nn.GRU(hidden_dim, hidden_dim, num_layers=num_layers)\n",
        "            self.rnn = gr\n",
        "        elif self.cell_type == \"LSTM\":\n",
        "            ls=nn.LSTM(hidden_dim, hidden_dim, num_layers=num_layers)\n",
        "            self.rnn = ls\n",
        "        else:\n",
        "            rn=nn.RNN(hidden_dim, hidden_dim, num_layers=num_layers)\n",
        "            self.rnn = rn\n",
        "\n",
        "        self.out = nn.Linear(hidden_dim, output_size)\n",
        "        \n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs): #input shape (1, batch_size) \n",
        "        # embedded shape (1, batch_size, embedding_dim)\n",
        "        embedded = F.relu(self.embedding(input.long()).view(-1, self.batch_size, self.embedding_dim))\n",
        "\n",
        "        # Compute attention scores\n",
        "        if self.cell_type == \"LSTM\":\n",
        "            attn_hidden = torch.mean(hidden[0], dim=0)\n",
        "        else:\n",
        "            attn_hidden = torch.mean(hidden, dim = 0)\n",
        "        vas=torch.cat((embedded, attn_hidden.unsqueeze(0)), dim=2)\n",
        "        attn_scores = self.attention(vas) # attn_scores shape (1, batch_size, max_length)\n",
        "        et=encoder_outputs.transpose(0, 1)\n",
        "        attn_weights = F.softmax(attn_scores, dim=0)  # attn_scores shape (1, 16, 25)\n",
        "        at=attn_weights.transpose(0, 1)\n",
        "\n",
        "        # Apply attention weights to encoder outputs\n",
        "        attn_applied = torch.bmm(at,et )\n",
        "        \n",
        "        # Combine attention output and embedded input\n",
        "        combined = torch.cat((embedded, attn_applied.transpose(0, 1)), dim=2)\n",
        "        combined = self.attention_combine(combined)\n",
        "        combined = F.relu(combined) # shape (1, batch_size, hidden_dim)\n",
        "\n",
        "        # Run through the RNN\n",
        "        output, hidden = self.rnn(combined, hidden)\n",
        "        # output shape: (1, batch_size, hidden_dim)\n",
        "\n",
        "        # Pass through linear layer and softmax activation\n",
        "        output = self.out(output)  # shape: (1, batch_size, output_size)\n",
        "        output = self.softmax(output)\n",
        "\n",
        "        return output, hidden, attn_weights\n"
      ],
      "metadata": {
        "id": "CGAlVAmAzUE_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_exact_matches(pred, target):\n",
        "    \"\"\"\n",
        "    Counts the number of exact matches between the rows of the preds tensor and the y tensor.\n",
        "    pred: tensor of shape (batch_size, seq_len)\n",
        "            Tensor containing predicted values.\n",
        "    target: tensor of shape (batch_size, seq_len)\n",
        "            Tensor containing target values.\n",
        "    Returns:Number of rows in the preds tensor that match exactly with each row in the target tensor.\n",
        "    \"\"\"\n",
        "    len1=pred.shape[0]\n",
        "    count=0;\n",
        "    for i in range(len1):\n",
        "      len2=pred.shape[1]\n",
        "      flag = True\n",
        "      for j in range(len2):\n",
        "        if(target[i][j]!=pred[i][j]):\n",
        "          flag=False\n",
        "          break;\n",
        "      x=1\n",
        "      if(flag):\n",
        "        count+=x;\n",
        "    \n",
        "    return count\n"
      ],
      "metadata": {
        "id": "mYmuGieMo3PN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the performance of the encoder-decoder model on the given data.\n",
        "def evaluate_model(data,encoder, decoder,output_size,batch_size,hidden_dim,num_encoders,num_decoders, cell_type,attention):\n",
        "    \n",
        "    loader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
        "    running_loss = 0\n",
        "    correct =0\n",
        "    loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "    total=0\n",
        "\n",
        "    seq_len = 0\n",
        "    with torch.no_grad():\n",
        "      for j,(x,y) in enumerate(loader):\n",
        "        loss=0\n",
        "        encoder.eval()\n",
        "        val= num_decoders - num_encoders\n",
        "        decoder.eval()\n",
        "\n",
        "        x = x.to(device)\n",
        "        x = x.T\n",
        "\n",
        "        y = y.to(device)\n",
        "        y = y.T\n",
        "        seq_len = len(y)\n",
        "        \n",
        "        encoder_hidden=encoder.initialize_hidden()\n",
        "        decoder_input =y[0]\n",
        "        encoder_output,encoder_hidden = encoder(x,encoder_hidden)\n",
        "        \n",
        "        # Handle different numbers of layers in the encoder and decoder\n",
        "        if num_encoders == num_decoders:\n",
        "            decoder_hidden = encoder_hidden \n",
        "        else:\n",
        "            if num_encoders > num_decoders:\n",
        "                # Slice the hidden states of the encoder to match the decoder layers\n",
        "                if cell_type != \"LSTM\":\n",
        "                    decoder_hidden = encoder_hidden[-num_decoders:]\n",
        "                else :\n",
        "                    decoder_hidden = (encoder_hidden[0][-num_decoders:], encoder_hidden[1][-num_decoders:])\n",
        "            else:\n",
        "                \n",
        "                # Copy all encoder hidden layers and then repeat the top layer\n",
        "                if cell_type != \"LSTM\":\n",
        "                    remaining_layers = val\n",
        "                    top_layer_hidden = encoder_hidden[-1].unsqueeze(0) #top_layer_hidden shape (1, batch_size, hidden_dim)\n",
        "                    extra_hidden = top_layer_hidden.repeat(remaining_layers, 1, 1)\n",
        "                    dm=0\n",
        "                    decoder_hidden = torch.cat((encoder_hidden, extra_hidden), dim=dm) \n",
        "                else:  \n",
        "                    top_layer_hidden_h = encoder_hidden[0][-1].unsqueeze(0)\n",
        "                    top_layer_hidden_c = encoder_hidden[1][-1].unsqueeze(0)\n",
        "                    top_layer_hidden = (top_layer_hidden_h, top_layer_hidden_c)\n",
        "                    remaining_layers = val\n",
        "                    extra_hidden = (top_layer_hidden[0].repeat(remaining_layers, 1, 1), top_layer_hidden[1].repeat(remaining_layers, 1, 1))\n",
        "                    dm=0\n",
        "                    decoder_hidden = (torch.cat((encoder_hidden[0], extra_hidden[0]), dim=dm), torch.cat((encoder_hidden[1], extra_hidden[1]), dim=dm))\n",
        "\n",
        "        sm=len(y)\n",
        "        pred=torch.zeros(sm-1, batch_size)\n",
        "\n",
        "        for k in range(1,sm):\n",
        "          if attention == \"Yes\":\n",
        "              decoder_output, decoder_hidden, atten_weights = decoder(decoder_input, decoder_hidden, encoder_output)\n",
        "          else:\n",
        "              decoder_output, decoder_hidden= decoder(decoder_input, decoder_hidden)\n",
        "          lp=y[k].long()\n",
        "          max_prob, index = decoder_output.topk(1) # max_prob shape (1, batch_size, 1)\n",
        "          decoder_output = torch.squeeze(decoder_output)\n",
        "          ind =k-1\n",
        "          loss += loss_fun(decoder_output,lp)\n",
        "          pred[ind]= torch.squeeze(index)\n",
        "          decoder_input = index\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        rs=y[1:,:].T\n",
        "        correct += calculate_exact_matches(pred.T,rs)\n",
        "\n",
        "    si= len(data) \n",
        "    den = (si* seq_len)    \n",
        "    avg_loss = running_loss / den \n",
        "    #print(\"correct =\", correct)\n",
        "    num=correct / (si)\n",
        "    avg_acc = 100 *num \n",
        "    return avg_loss, avg_acc"
      ],
      "metadata": {
        "id": "pi-EbiYVpADH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(sweeps = True, test = False):\n",
        "    \n",
        "    if sweeps == True: \n",
        "        wandb.init(config= config_defaults, project='DL_assign_3')   # if not test then run wandb sweeps\n",
        "        configs=wandb.config    \n",
        "    else:\n",
        "        configs = config_defaults  # use the default configuration which has the best hyperparameters\n",
        "    nd= configs['num_decoders']  \n",
        "    num_decoders = nd\n",
        "    lr=configs['learn_rate']\n",
        "    learn_rate = lr\n",
        "    bd=configs['bidirectional']\n",
        "    bidirectional = bd\n",
        "    ed=configs['embedding_dim']\n",
        "    embedding_dim = ed\n",
        "    tr=configs['teach_ratio']\n",
        "    teach_ratio =tr \n",
        "    ct=configs['cell_type']\n",
        "    cell_type = ct\n",
        "    hd=configs['hidden_dim']\n",
        "    hidden_dim =hd\n",
        "    ne= configs['num_encoders']\n",
        "    num_encoders = ne\n",
        "    ep=configs['epochs']\n",
        "    epochs = ep\n",
        "    bs= configs['batch_size']\n",
        "    batch_size =bs\n",
        "    attention = configs['attention']\n",
        "    dropout = configs['dropout']\n",
        "    print(f\"batch size {batch_size}, hidden size {hidden_dim}\")\n",
        "\n",
        "    input_len = ipLang.n_chars\n",
        "    if sweeps:\n",
        "       wandb.run.name='hidden_'+str(hidden_dim)+'_batch_'+str(batch_size)+'_embed_size_'+str(embedding_dim)+'_dropout_'+str(dropout)+'_cell_'+str(cell_type)\n",
        "    \n",
        "    encoder = MyEncoder(input_len, hidden_dim, embedding_dim, \n",
        "                 num_encoders, cell_type,\n",
        "                  bidirectional, dropout, batch_size)\n",
        "    output_len = opLang.n_chars\n",
        "    if attention ==\"Yes\":\n",
        "        decoder = AttentionDecoderRNN(hidden_dim, output_len, embedding_dim, num_decoders, \n",
        "                 cell_type, dropout, batch_size, 25)\n",
        "    else:\n",
        "        decoder = MyDecoder(hidden_dim, output_len, embedding_dim, num_decoders, \n",
        "                 cell_type, dropout, batch_size)#dropout not used\n",
        "    \n",
        "    encoder_optimizer=optim.Adam(encoder.parameters(),learn_rate)\n",
        "    train_loader = DataLoader(trainData, batch_size=batch_size, shuffle=True)\n",
        "    \n",
        "    loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")    \n",
        "    encoder.to(device)\n",
        "    seq_len = 0\n",
        "    decoder_optimizer=optim.Adam(decoder.parameters(),learn_rate)\n",
        "    val_loader = DataLoader(valData, batch_size=batch_size, shuffle=True)\n",
        "    decoder.to(device)\n",
        "\n",
        "    # Initialize variables for early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 5\n",
        "    epochs_without_improvement = 0\n",
        "    \n",
        "    for i in range(epochs):\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        train_correct = 0\n",
        "\n",
        "        encoder.train()\n",
        "        bq= enumerate(train_loader)\n",
        "        decoder.train()\n",
        "\n",
        "        for j,(train_x,train_y) in bq:\n",
        "            \n",
        "            val=num_decoders - num_encoders\n",
        "            train_x = train_x.to(device)\n",
        "            train_x=train_x.T\n",
        "            encoder_optimizer.zero_grad()\n",
        "            train_y = train_y.to(device)\n",
        "            train_y=train_y.T\n",
        "            seq_len = len(train_y)\n",
        "            # lets move to the decoder\n",
        "            decoder_input = train_y[0]\n",
        "\n",
        "            decoder_optimizer.zero_grad()\n",
        "            \n",
        "            encoder_hidden=encoder.initialize_hidden()\n",
        "            encoder_output,encoder_hidden = encoder(train_x,encoder_hidden)\n",
        "            \n",
        "            \n",
        "            # Handle different numbers of layers in the encoder and decoder\n",
        "            if num_encoders == num_decoders:\n",
        "                decoder_hidden = encoder_hidden\n",
        "                \n",
        "            else:\n",
        "                if num_encoders > num_decoders:\n",
        "                    # Slice the hidden states of the encoder to match the decoder layers\n",
        "                    if cell_type != \"LSTM\":\n",
        "                        decoder_hidden = encoder_hidden[-num_decoders:]\n",
        "                    else :\n",
        "                        decoder_hidden = (encoder_hidden[0][-num_decoders:], encoder_hidden[1][-num_decoders:])\n",
        "                else:\n",
        "                    \n",
        "                    # Copy all encoder hidden layers and then repeat the top layer\n",
        "                    if cell_type != \"LSTM\":\n",
        "                        remaining_layers = val\n",
        "                        top_layer_hidden = encoder_hidden[-1].unsqueeze(0) #top_layer_hidden shape (1, batch_size, hidden_dim)\n",
        "                        extra_hidden = top_layer_hidden.repeat(remaining_layers, 1, 1)\n",
        "                        dm=0\n",
        "                        decoder_hidden = torch.cat((encoder_hidden, extra_hidden), dim=dm)\n",
        "                    else:\n",
        "                        top_layer_hidden_h = encoder_hidden[0][-1].unsqueeze(0)\n",
        "                        top_layer_hidden_c = encoder_hidden[1][-1].unsqueeze(0)\n",
        "                        top_layer_hidden = (top_layer_hidden_h, top_layer_hidden_c)\n",
        "                        remaining_layers = val\n",
        "                        extra_hidden = (top_layer_hidden[0].repeat(remaining_layers, 1, 1), top_layer_hidden[1].repeat(remaining_layers, 1, 1))\n",
        "                        dm=0\n",
        "                        decoder_hidden = (torch.cat((encoder_hidden[0], extra_hidden[0]), dim=dm), torch.cat((encoder_hidden[1], extra_hidden[1]), dim=dm))\n",
        "\n",
        "            loss = 0\n",
        "            sg=len(train_y)-1\n",
        "            correct = 0\n",
        "           \n",
        "            for k in range(0,sg ):\n",
        "                \n",
        "                if attention == \"Yes\":\n",
        "                    decoder_output, decoder_hidden, atten_weights = decoder(decoder_input, decoder_hidden, encoder_output)\n",
        "                else:\n",
        "                    decoder_output, decoder_hidden= decoder(decoder_input, decoder_hidden) # decoder_output shape (1, batch_size, output_size)\n",
        "\n",
        "                pq=torch.squeeze(decoder_output)\n",
        "                max_prob, index = decoder_output.topk(1) # max_prob shape (1, batch_size, 1)\n",
        "                rs= train_y[k+1].long()\n",
        "                index = torch.squeeze(index) # shape (batch_size)\n",
        "                # Apply teacher forcing\n",
        "                use_teacher_forcing = True if random.random() < teach_ratio else False\n",
        "                decoder_output = pq\n",
        "                loss += loss_fun(decoder_output,rs)\n",
        "                \n",
        "                correct += (index == train_y[k+1]).sum().item()\n",
        "\n",
        "                \n",
        "                if use_teacher_forcing:\n",
        "                    decoder_input = train_y[k+1]\n",
        "                \n",
        "                else:\n",
        "                    decoder_input = index\n",
        "\n",
        "            train_correct =train_correct + correct\n",
        "            running_loss =running_loss+ loss.item()\n",
        "            decoder_optimizer.step()\n",
        "            loss.backward()\n",
        "            encoder_optimizer.step()\n",
        "            \n",
        "        # find train loss and accuracy and print + log to wandb\n",
        "        _, train_accuracy = evaluate_model(trainData,encoder, decoder,output_len,batch_size,hidden_dim,num_encoders,num_decoders, cell_type, attention)\n",
        "        train_loss=running_loss/(len(trainData)* seq_len)\n",
        "        print(\"After \",i+1,\"epoch:\")\n",
        "        print(\"training loss:\",train_loss)\n",
        "        print(\"training accuracyy:\",train_accuracy)\n",
        "        if sweeps:\n",
        "            wandb.log({\"epoch\": i, \"train_loss\": train_loss, \"train_accuracy\": train_accuracy})\n",
        "        \n",
        "        # find validation loss and accuracy and print + log to wandb\n",
        "        val_loss, val_accuracy = evaluate_model(valData,encoder, decoder,output_len,batch_size,hidden_dim,num_encoders,num_decoders, cell_type, attention)\n",
        "        print(\"validation loss:\",val_loss)\n",
        "        print(\"validation accuracy:\",val_accuracy)\n",
        "        if sweeps:\n",
        "            wandb.log({\"val_loss\": val_loss, \"val_accuracy\": val_accuracy})\n",
        "        \n",
        "        # Check for early stopping\n",
        "        if val_loss > best_val_loss:\n",
        "            epochs_without_improvement += 1\n",
        "            patience=5\n",
        "            if epochs_without_improvement >= patience:\n",
        "                print(\"Early stopping triggered. No improvement in validation loss.\")\n",
        "                break \n",
        "        else:\n",
        "            epochs_without_improvement = 0\n",
        "            best_val_loss = val_loss\n",
        "            # Save the model weights\n",
        "            torch.save(encoder.state_dict(), 'best_encoder.pt')\n",
        "            torch.save(decoder.state_dict(), 'best_decoder.pt')\n",
        "    # if testing mode is on print the test accuracy \n",
        "    if test:\n",
        "        # Load the best model weights\n",
        "        encoder.load_state_dict(torch.load('best_encoder.pt'))\n",
        "        decoder.load_state_dict(torch.load('best_decoder.pt'))\n",
        "        _, test_accuracy = evaluate_model(testData,encoder, decoder,output_len,batch_size,hidden_dim,num_encoders,num_decoders, bidirectional, cell_type)\n",
        "        print(f\"test accuracy {test_accuracy}\")"
      ],
      "metadata": {
        "id": "kSrEMI5qpLVt"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(sweeps = False, test = True)"
      ],
      "metadata": {
        "id": "ja3sNgQlEajP"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sweep_id=wandb.sweep(sweep_config, project=\"Assignment_3\")\n",
        "# wandb.agent(sweep_id,function=train)\n",
        "wandb.agent(sweep_id= \"3rd4g4gq\",function=train, project=\"Assignment_3\")"
      ],
      "metadata": {
        "id": "CCq_NFKlpaCK"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing the Best Model on Test Data"
      ],
      "metadata": {
        "id": "4A45jj7daz6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(test = True)"
      ],
      "metadata": {
        "id": "RgLgU3MdleY3"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnDecoder(nn.Module):\n",
        "    def __init__(self,output_size,hidden_dim,embedding_dim,decoder_layers,batch_size,cell_type,dropout_p=0.1):\n",
        "        super(AttnDecoder, self).__init__()\n",
        "        x=hidden_dim\n",
        "        self.hidden_dim = x\n",
        "        y=output_size\n",
        "        self.output_size = y\n",
        "        r=dropout_p\n",
        "        self.dropout_p = r\n",
        "        s=batch_size\n",
        "        self.batch_size=s \n",
        "        t=cell_type\n",
        "        self.U=nn.Linear(self.hidden_dim,self.hidden_dim,bias=False).to(device)\n",
        "        self.cell_type=t\n",
        "        \n",
        "        u=embedding_dim\n",
        "        self.embedding_dim= u\n",
        "        self.softmax=nn.LogSoftmax()\n",
        "        v=decoder_layers\n",
        "        self.W=nn.Linear(self.hidden_dim,self.hidden_dim,bias=False).to(device)\n",
        "        self.decoder_layers=v\n",
        "        \n",
        "        l=nn.Embedding(self.output_size, self.embedding_dim)\n",
        "        self.embedding = l\n",
        "        p= nn.Dropout(self.dropout_p)\n",
        "        self.V=nn.Linear(self.hidden_dim,1,bias=False).to(device)\n",
        "        self.dropout = p\n",
        "        \n",
        "        self.linear=nn.Linear(self.hidden_dim,output_size,bias=True)\n",
        "        self.softmax1=nn.LogSoftmax(dim=2)\n",
        "        if(cell_type==\"GRU\"):\n",
        "            gr=nn.GRU(self.embedding_dim+self.hidden_dim, self.hidden_dim,self.decoder_layers,dropout = dropout_p)\n",
        "            self.gru = gr\n",
        "        if(cell_type==\"LSTM\"):\n",
        "            ls=nn.LSTM(self.embedding_dim+self.hidden_dim, self.hidden_dim,self.decoder_layers,dropout = dropout_p)\n",
        "            self.lstm = ls\n",
        "        if(cell_type==\"RNN\"):\n",
        "            rn=nn.RNN(self.embedding_dim+self.hidden_dim, self.hidden_dim,self.decoder_layers,dropout = dropout_p)\n",
        "            self.rnn = rn\n",
        "\n",
        "    def forward(self, input, hidden,encoder_outputs,word_length,state=None):\n",
        "        T=word_length\n",
        "        embedded = self.embedding(input).view(-1,self.batch_size, self.embedding_dim)\n",
        "#         embedded = self.dropout(embedded)\n",
        "        c=torch.zeros(self.batch_size,self.hidden_dim).to(device)\n",
        "        temp=self.W(hidden[-1])\n",
        "        \n",
        "        for j in range(0,T):\n",
        "            mk=(encoder_outputs[j])+temp\n",
        "            e_j=self.V(torch.tanh(self.U(mk)))\n",
        "            c+=self.softmax(e_j)*encoder_outputs[j]\n",
        "        \n",
        "\n",
        "        final_input=torch.cat((embedded,c.unsqueeze(0)),dim=2)\n",
        "        \n",
        "        \n",
        "        if(self.cell_type==\"GRU\"):\n",
        "            gr=self.gru(final_input,hidden)\n",
        "            output,hidden=gr\n",
        "        if(self.cell_type==\"RNN\"):\n",
        "            rn=self.rnn(final_input,hidden)\n",
        "            output,hidden=rn\n",
        "        if(self.cell_type==\"LSTM\"):\n",
        "            ls=self.lstm(final_input,(hidden,state))\n",
        "            output, (hidden,state) =ls\n",
        "        \n",
        "        output1=self.softmax1(self.linear(output))\n",
        "        \n",
        "        if(self.cell_type==\"GRU\" or self.cell_type==\"RNN\"):\n",
        "            return output1, hidden, c\n",
        "        if(self.cell_type==\"LSTM\"):\n",
        "            return output1, hidden, state, c\n"
      ],
      "metadata": {
        "id": "NywVetHb36ue"
      },
      "execution_count": 47,
      "outputs": []
    }
  ]
}